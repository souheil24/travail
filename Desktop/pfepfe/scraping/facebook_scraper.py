import requests
import time
import json
from datetime import datetime
import os
import django
import sys

# ğŸ‘‰ Configuration personnalisable
ACCESS_TOKEN = "EAAOa69C97g4BO3vQmZBEGrYJynS3VWr7HZCn2ZAtkmXQDc5VujNmcPoPdUVnVw0kuKYtW46lGYhIqZATCWn9NWZBS7MkigS2fykag5ZBOU6CZCCS9LZAf9n72Pv9AO2ukiT7ZC6r6lLzgtYWCiqeaHylhKomC2KvqDU1ZCL7wOd7HZCeZBIVMpwDJLRjZCcdw98whZCJoZD"
PAGE_ID = "106515182375055"
GRAPH_URL = "https://graph.facebook.com/v19.0"
OUTPUT_DIR = "facebook_data"  # Dossier pour sauvegarder les donnÃ©es
RATE_LIMIT_DELAY = 1  # DÃ©lai entre les requÃªtes pour Ã©viter les limites de taux (en secondes)

# CrÃ©er le dossier de sortie s'il n'existe pas
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ğŸ”¹ Fonction pour gÃ©rer les erreurs d'API
def handle_api_error(response_data):
    if "error" in response_data:
        error = response_data["error"]
        print(f"âŒ Erreur API: {error.get('message', 'Erreur inconnue')} (Code: {error.get('code', 'inconnu')})")
        
        # VÃ©rifier si le token est expirÃ©
        if error.get('code') == 190:
            print("ğŸ”‘ Le token d'accÃ¨s semble Ãªtre expirÃ© ou invalide. Veuillez gÃ©nÃ©rer un nouveau token.")
        
        # VÃ©rifier si on a atteint une limite de taux
        if error.get('code') == 4 or error.get('code') == 17:
            wait_time = 60  # Attendre 1 minute par dÃ©faut
            print(f"â±ï¸ Limite de taux atteinte. Attente de {wait_time} secondes...")
            time.sleep(wait_time)
            return True  # Indique qu'il faut rÃ©essayer
        
        return False  # Ne pas rÃ©essayer pour les autres erreurs
    return False

# ğŸ”¹ Fonction pour effectuer des requÃªtes API avec gestion des erreurs
def make_api_request(url, params=None, retry_count=0, max_retries=3):
    try:
        # Attendre pour respecter les limites de taux
        time.sleep(RATE_LIMIT_DELAY)
        
        # Effectuer la requÃªte
        response = requests.get(url, params=params if '?' not in url else None)
        data = response.json()
        
        # GÃ©rer les erreurs
        if handle_api_error(data) and retry_count < max_retries:
            return make_api_request(url, params, retry_count + 1, max_retries)
        
        return data
    except Exception as e:
        print(f"âŒ Erreur lors de la requÃªte: {str(e)}")
        if retry_count < max_retries:
            wait_time = 5 * (retry_count + 1)
            print(f"â±ï¸ Tentative de reconnexion dans {wait_time} secondes...")
            time.sleep(wait_time)
            return make_api_request(url, params, retry_count + 1, max_retries)
        return {"data": []}

# ğŸ”¹ VÃ©rifier la validitÃ© du token d'accÃ¨s
def verify_token():
    url = f"{GRAPH_URL}/debug_token"
    params = {
        "input_token": ACCESS_TOKEN,
        "access_token": ACCESS_TOKEN
    }
    
    response = make_api_request(url, params)
    
    if "data" in response:
        token_data = response["data"]
        if token_data.get("is_valid", False):
            expires_at = token_data.get("expires_at", 0)
            
            if expires_at == 0:
                print("âœ… Token d'accÃ¨s valide (ne expire pas)")
            else:
                expires_date = datetime.fromtimestamp(expires_at)
                print(f"âœ… Token d'accÃ¨s valide jusqu'au {expires_date}")
            
            scopes = token_data.get('scopes', [])
            print(f"ğŸ”“ Permissions: {', '.join(scopes)}")
            
            return True
        else:
            print("âŒ Token d'accÃ¨s invalide")
            return False
    else:
        print("âŒ Impossible de vÃ©rifier le token d'accÃ¨s")
        return False

# ğŸ”¹ RÃ©cupÃ©rer tous les posts de la page avec pagination complÃ¨te
def get_all_posts(since_date=None):
    posts = []
    url = f"{GRAPH_URL}/{PAGE_ID}/posts"
    params = {
        "access_token": ACCESS_TOKEN,
        "fields": "id,message,full_picture,created_time,permalink_url,attachments{type,url,media,title,description},shares",
        "limit": 100  # Utiliser la limite maximale pour rÃ©duire le nombre de requÃªtes
    }
    
    # Ajouter un filtre de date si spÃ©cifiÃ©
    if since_date:
        params["since"] = since_date
    
    page_count = 0
    print("ğŸ“ƒ RÃ©cupÃ©ration des posts...")
    
    while url:
        page_count += 1
        print(f"  Page {page_count} de posts en cours de chargement...")
        
        data = make_api_request(url, params if '?' not in url else None)
        new_posts = data.get("data", [])
        posts.extend(new_posts)
        print(f"  â• {len(new_posts)} posts ajoutÃ©s")
        
        # Obtenir l'URL pour la prochaine page
        url = data.get("paging", {}).get("next")
    
    print(f"âœ… Total de {len(posts)} posts rÃ©cupÃ©rÃ©s")
    return posts

# ğŸ”¹ Nettoyer le texte des commentaires (mots/noms Ã  remplacer)
def clean_comment_text(text):
    # Liste de mots communs qui peuvent Ãªtre des noms (Ã  adapter selon vos besoins)
    common_names = [
        # Ajoutez ici les noms que vous voulez explicitement remplacer
        # Par exemple votre nom, prÃ©nom, etc.
    ]
    
    # Remplacer les mentions et les tags
    text = text.replace("@", "")
    
    # Remplacer les noms spÃ©cifiques
    for name in common_names:
        if name in text:
            text = text.replace(name, "quelqu'un")
    
    return text

# ğŸ”¹ RÃ©cupÃ©rer tous les commentaires d'un post, y compris les rÃ©ponses aux commentaires
def get_all_comments(post_id):
    all_comments = []
    url = f"{GRAPH_URL}/{post_id}/comments"
    params = {
        "access_token": ACCESS_TOKEN,
        # Ne demandons plus les informations sur l'auteur
        "fields": "id,message,attachment,created_time,like_count,comment_count",
        "limit": 100,
        "order": "chronological"  # Pour avoir les commentaires dans l'ordre chronologique
    }
    
    comment_count = 0
    page_count = 0
    
    print(f"  ğŸ’¬ RÃ©cupÃ©ration des commentaires pour le post {post_id}...")
    
    while url:
        page_count += 1
        data = make_api_request(url, params if '?' not in url else None)
        comments = data.get("data", [])
        
        # Anonymiser les commentaires et nettoyer le texte
        for comment in comments:
            # Supprimer complÃ¨tement le champ "from" s'il existe
            if "from" in comment:
              comment["author_id"] = comment["from"].get("id", "inconnu")
              del comment["from"]
            
            # Ajouter un champ uniformisÃ© pour l'auteur
            comment["author"] = "commentateur"
            
            # Nettoyer le texte du commentaire
            if "message" in comment:
                comment["message"] = clean_comment_text(comment["message"])
        
        all_comments.extend(comments)
        comment_count += len(comments)
        
        # Obtenir l'URL pour la prochaine page
        url = data.get("paging", {}).get("next")
        
        if page_count % 5 == 0:
            print(f"    Page {page_count}, {comment_count} commentaires rÃ©cupÃ©rÃ©s jusqu'Ã  prÃ©sent")
    
    # RÃ©cupÃ©rer les rÃ©ponses aux commentaires (pour chaque commentaire principal)
    for comment in list(all_comments):
        # Ne traiter que les commentaires de premier niveau (qui n'ont pas de parent)
        if "parent" not in comment and comment.get("comment_count", 0) > 0:
            replies = get_comment_replies(comment["id"])
            all_comments.extend(replies)
    
    print(f"  âœ… Total de {len(all_comments)} commentaires et rÃ©ponses rÃ©cupÃ©rÃ©s")
    return all_comments

# ğŸ”¹ RÃ©cupÃ©rer les rÃ©ponses Ã  un commentaire spÃ©cifique
def get_comment_replies(comment_id):
    replies = []
    url = f"{GRAPH_URL}/{comment_id}/comments"
    params = {
        "access_token": ACCESS_TOKEN,
        # Ne demandons plus les informations sur l'auteur
        "fields": "id,message,attachment,created_time,like_count,comment_count,parent",
        "limit": 100
    }
    
    while url:
        data = make_api_request(url, params if '?' not in url else None)
        comments_data = data.get("data", [])
        
        # Anonymiser les rÃ©ponses et nettoyer le texte
        for comment in comments_data:
           # RÃ©cupÃ©rer uniquement l'ID de l'auteur s'il existe
            if "from" in comment and isinstance(comment["from"], dict):
                comment["author_id"] = comment["from"].get("id", "inconnu")
                del comment["from"]  # Supprimer tout le reste (nom, etc.)
                
            # Ajouter un champ uniformisÃ© pour l'auteur
            comment["author"] = "commentateur"
            
            # Nettoyer le texte du commentaire
            if "message" in comment:
                comment["message"] = clean_comment_text(comment["message"])
        
        replies.extend(comments_data)
        url = data.get("paging", {}).get("next")
    
    return replies

# ğŸ”¹ RÃ©cupÃ©rer les dÃ©tails complets d'un post
def get_post_details(post_id):
    url = f"{GRAPH_URL}/{post_id}"
    params = {
        "access_token": ACCESS_TOKEN,
        "fields": "id,message,full_picture,created_time,permalink_url,likes.summary(true),comments.summary(true),shares,attachments{type,url,media,title,description}"
    }
    
    post_data = make_api_request(url, params)
    
    # Si le post contient un message, nettoyons-le aussi
    if "message" in post_data:
        post_data["message"] = clean_comment_text(post_data["message"])
        
    return post_data

# ğŸ”¹ Sauvegarder les donnÃ©es dans un fichier JSON
def save_to_json(data, filename):
    file_path = os.path.join(OUTPUT_DIR, filename)
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ DonnÃ©es sauvegardÃ©es dans {file_path}")

# ğŸ”¹ Afficher les donnÃ©es d'un post et ses commentaires
def display_post_info(post_data, comments):
    print(f"\nğŸ”¹ Post ID: {post_data.get('id')}")
    print(f"ğŸ“ Message: {post_data.get('message', 'Pas de message')}")
    print(f"ğŸ–¼ï¸ MÃ©dia: {post_data.get('full_picture', 'Aucun')}")
    print(f"â° CrÃ©ation: {post_data.get('created_time')}")
    print(f"ğŸ”— URL: {post_data.get('permalink_url', 'Non disponible')}")
    
    likes = post_data.get('likes', {}).get('summary', {}).get('total_count', 0)
    comment_count = post_data.get('comments', {}).get('summary', {}).get('total_count', 0)
    shares = post_data.get('shares', {}).get('count', 0) if 'shares' in post_data else 0
    
    print(f"â¤ï¸ Likes: {likes}")
    print(f"ğŸ’¬ Commentaires (total selon Facebook): {comment_count}")
    print(f"ğŸ”„ Partages: {shares}")
    print(f"ğŸ“Š Commentaires rÃ©cupÃ©rÃ©s: {len(comments)}")
    
    if len(comments) < comment_count:
        print(f"âš ï¸ Attention: {comment_count - len(comments)} commentaires manquants!")
    
    # Afficher le nombre de commentaires seulement (pas d'IDs)
    print(f"\nğŸ‘¥ {len(comments)} commentaires rÃ©cupÃ©rÃ©s au total")
    
    # Afficher les 3 premiers commentaires (si disponibles)
    if comments:
        print("\nğŸ“ Exemples de commentaires:")
        for i, comment in enumerate(comments[:3]):
            message = comment.get('message', 'Pas de message')
            likes = comment.get('like_count', 0)
            created = comment.get('created_time', 'Date inconnue')
            
            # Afficher juste "commentateur" pour tous
            print(f"  {i+1}. commentateur ({created}): {message[:50]}{'...' if len(message) > 50 else ''} ({likes} ğŸ‘)")

# ğŸ”¹ CrÃ©ation dâ€™un post Facebook
def create_facebook_post_api(message, image_url=None):
    print("envoie du post a facebook")
    url = f"{GRAPH_URL}/{PAGE_ID}/feed"
    params = {
        "access_token": ACCESS_TOKEN,
        "message": message,
    }

    if image_url:
        params["picture"] = image_url

    response = requests.post(url, data=params)
    data = response.json()

    if "id" in data:
        print(f"âœ… Post crÃ©Ã© avec succÃ¨s : {data['id']}")
        return data["id"]
    else:
        print(f"âŒ Erreur lors de la crÃ©ation du post : {data}")
        return None

def publish_photo_with_message(message, image_path):
    print("ğŸ“· Envoi d'une image rÃ©elle Ã  Facebook...")
    print(f"ğŸ“ Fichier image Ã  envoyer : {image_path}")
    print(f"ğŸ“¦ Taille : {os.path.getsize(image_path) / 1024:.2f} Ko")


    url = f"{GRAPH_URL}/{PAGE_ID}/photos"
    files = {
        'source': open(image_path, 'rb')  # fichier binaire
    }
    params = {
        "access_token": ACCESS_TOKEN,
        "message": message,
    }

    response = requests.post(url, files=files, data=params, timeout=20)
    data = response.json()

    print("ğŸ“¨ RÃ©ponse Facebook (photo) :", data)

    if "post_id" in data:
        return data["post_id"]
    else:
        return None

# ğŸ”¹ Suppression dâ€™un post Facebook
def delete_facebook_post(post_id):
    url = f"{GRAPH_URL}/{post_id}"
    params = {
        "access_token": ACCESS_TOKEN
    }

    response = requests.delete(url, params=params)
    data = response.json()

    if data.get("success"):
        print("ğŸ—‘ï¸ Post supprimÃ© avec succÃ¨s")
        return True
    else:
        print("âŒ Ã‰chec de la suppression :", data)
        return False

# ğŸ”¹ Traitement principal
def main():
    print("ğŸš€ DÃ©but de la rÃ©cupÃ©ration des donnÃ©es Facebook")
    
    # VÃ©rifier que le token est valide avant de continuer
    if not verify_token():
        print("âŒ Impossible de continuer avec un token invalide.")
        return
    
    # RÃ©cupÃ©rer tous les posts (on peut spÃ©cifier une date de dÃ©but en format ISO, ex: "2023-01-01")
    posts = get_all_posts()
    
    # PrÃ©parer les donnÃ©es complÃ¨tes
    all_data = []
    
    # Pour chaque post, rÃ©cupÃ©rer ses dÃ©tails et commentaires
    for i, post in enumerate(posts):
        post_id = post["id"]
        print(f"\nâ³ Traitement du post {i+1}/{len(posts)} (ID: {post_id})")
        
        # RÃ©cupÃ©rer les dÃ©tails complets du post
        post_data = get_post_details(post_id)
        
        # RÃ©cupÃ©rer tous les commentaires du post
        comments = get_all_comments(post_id)
        
        # Afficher les informations
        display_post_info(post_data, comments)
        
        # Stocker les donnÃ©es du post et ses commentaires
        post_data["fetched_comments"] = comments
        all_data.append(post_data)
        
        # Sauvegarder les donnÃ©es du post individuellement
        save_to_json(post_data, f"post_{post_id.split('_')[-1]}.json")
        
        # Pause pour Ã©viter de surcharger l'API
        if i < len(posts) - 1:
            time.sleep(RATE_LIMIT_DELAY * 2)
    
    # Sauvegarder toutes les donnÃ©es
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_to_json(all_data, f"all_posts_{timestamp}.json")
    
    print(f"\nâœ… RÃ©cupÃ©ration terminÃ©e! {len(all_data)} posts traitÃ©s avec leurs commentaires.")
    print(f"ğŸ“Š Les fichiers JSON ont Ã©tÃ© sauvegardÃ©s dans le dossier '{OUTPUT_DIR}'.")



# Fonction pour Ãªtre appelÃ©e depuis views.py
def scrape_facebook():
    # Appeler la fonction main et retourner les donnÃ©es formatÃ©es
    return main()

if __name__ == "__main__":
    main()

# âš™ï¸ Configuration Django pour accÃ©der aux modÃ¨les
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # RÃ©pertoire du projet
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "PFE_APP.settings")  # Remplace par le nom de ton projet Django
django.setup()

from scraping.models import FacebookComment  # modÃ¨le Ã  crÃ©er (voir plus bas)

# ğŸ”¹ Fonction pour sauvegarder les donnÃ©es dans la base de donnÃ©es
def save_data_to_db(post_data, comments):
    post_id = post_data.get("id")
    media_url = post_data.get("full_picture", None)
    post_likes = post_data.get("likes", {}).get("summary", {}).get("total_count", 0)

    for comment in comments:
        FacebookComment.objects.create(
             post_id=post_id,
             media_url=media_url,
             comment_id=comment.get("id"),
             commenter_id=comment.get("author_id", "anonyme"),  # author_id uniquement
             comment_text=comment.get("message", ""),
             comment_likes=comment.get("like_count", 0),
             post_likes=post_likes,
        )
    print(f"ğŸ’¾ {len(comments)} commentaires sauvegardÃ©s en base de donnÃ©es.")

# ğŸ”¹ Modifie la fonction `main()` pour qu'elle retourne les donnÃ©es des commentaires
def main():
    print("ğŸš€ DÃ©but de la rÃ©cupÃ©ration des donnÃ©es Facebook")
    
    if not verify_token():
        return []  # Si le token est invalide, on retourne une liste vide.

    posts = get_all_posts()
    all_comments_data = []  # Liste pour stocker toutes les donnÃ©es des commentaires rÃ©cupÃ©rÃ©s

    for post in posts:
        post_id = post["id"]
        post_data = get_post_details(post_id)
        comments = get_all_comments(post_id)
        display_post_info(post_data, comments)
        
        # Sauvegarder dans la base de donnÃ©es
        save_data_to_db(post_data, comments)
        
        # Collecter les donnÃ©es des commentaires pour les renvoyer
        for comment in comments:
            comment_data = {
                "post_id": post_id,
                "media_url": post_data.get("full_picture", None),
                "comment_id": comment.get("id"),
                "commenter_id": comment.get("author_id", "anonyme"),  # Utilise author_id
                "comment_text": comment.get("message", ""),
                "comment_likes": comment.get("like_count", 0),
                "post_likes": post_data.get("likes", {}).get("summary", {}).get("total_count", 0),
            }
            all_comments_data.append(comment_data)

    return all_comments_data  # Renvoie la liste des commentaires collectÃ©s